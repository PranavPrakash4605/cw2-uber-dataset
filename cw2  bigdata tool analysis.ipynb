{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae884513-c254-4ec6-bb20-10df51365837",
   "metadata": {},
   "source": [
    "# Big data tool: PySpark(Apache Spark) to Analyze the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447f02a8-4ec1-4e0c-aa4e-27a942987fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pyspark in c:\\users\\y4z15\\appdata\\roaming\\python\\python38\\site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\y4z15\\appdata\\roaming\\python\\python38\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a453ce87-d9f5-4671-97df-c66005e24cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_timestamp, hour, dayofmonth, month, dayofweek, radians, sin, cos, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14543917-47c2-4814-96d0-cda8dd47b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Spark to Bind to Specific IP/Port to reduce firewall prompts\n",
    "import os\n",
    "os.environ['SPARK_LOCAL_IP'] = '127.0.0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be6d247-ffd5-4dd2-8344-18495571f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting Python interpreter for both PySpark driver and worker to match (3.11)\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"C:/Program Files/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"C:/Program Files/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2283453b-e9a8-4b5e-a2c2-c93500b02464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Starting the session \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"UberFareAnalysis\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837ca50c-f329-4762-8060-d52b336eae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load CSV\n",
    "df = spark.read.csv(\"uber.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df096d82-6080-453f-8ce8-79a8afc544e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Cleaning\n",
    "df = df.dropna()\n",
    "df = df.dropDuplicates()\n",
    "df = df.filter(col(\"fare_amount\") > 0)\n",
    "df = df.filter((col(\"passenger_count\") >= 1) & (col(\"passenger_count\") <= 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db4c816-b505-4a85-aa7a-f64e8b602717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC boundary filtering\n",
    "df = df.filter(\n",
    "    (col(\"pickup_longitude\").between(-75, -72)) &\n",
    "    (col(\"pickup_latitude\").between(40, 42)) &\n",
    "    (col(\"dropoff_longitude\").between(-75, -72)) &\n",
    "    (col(\"dropoff_latitude\").between(40, 42))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c1b0eb7-cb58-4f26-bd75-fdf633d06450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert to datetime and extract parts\n",
    "df = df.withColumn(\"pickup_datetime\", to_timestamp(\"pickup_datetime\"))\n",
    "df = df.dropna(subset=[\"pickup_datetime\"])\n",
    "df = df.withColumn(\"hour\", hour(\"pickup_datetime\")) \\\n",
    "       .withColumn(\"day\", dayofmonth(\"pickup_datetime\")) \\\n",
    "       .withColumn(\"month\", month(\"pickup_datetime\")) \\\n",
    "       .withColumn(\"weekday\", dayofweek(\"pickup_datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f11c51a-cb1a-48dc-bf5d-91315298c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Haversine Distance\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "import math\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(delta_phi/2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda/2)**2\n",
    "    return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "haversine_udf = udf(haversine, DoubleType())\n",
    "\n",
    "df = df.withColumn(\"distance_km\", haversine_udf(\n",
    "    col(\"pickup_latitude\"), col(\"pickup_longitude\"),\n",
    "    col(\"dropoff_latitude\"), col(\"dropoff_longitude\")\n",
    "))\n",
    "\n",
    "df = df.filter(col(\"distance_km\") > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ce11ee-1f33-421f-a78f-520ec49e1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Features and Label\n",
    "features = [\"passenger_count\", \"distance_km\", \"hour\", \"day\", \"month\"]\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5651e88b-c891-4498-b67b-29bd3d59a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c181e4b2-5e7b-468c-90d3-bf0e0dbac954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+-------------------+----------------+---------------+------------------+------------------+---------------+----+---+-----+-------+------------------+--------------------+\n",
      "|     _c0|                key|fare_amount|    pickup_datetime|pickup_longitude|pickup_latitude| dropoff_longitude|  dropoff_latitude|passenger_count|hour|day|month|weekday|       distance_km|            features|\n",
      "+--------+-------------------+-----------+-------------------+----------------+---------------+------------------+------------------+---------------+----+---+-----+-------+------------------+--------------------+\n",
      "|42367206|2014-09-23 00:15:52|       15.0|2014-09-23 01:15:52|      -73.994126|      40.750917|        -73.949428|40.781335999999996|              1|   1| 23|    9|      3| 5.060737421252564|[1.0,5.0607374212...|\n",
      "|51756123|2014-04-19 02:10:00|        9.0|2014-04-19 03:10:00|      -73.997222|      40.763667|-74.01061700000001|         40.730022|              3|   3| 19|    4|      7| 3.907626452664686|[3.0,3.9076264526...|\n",
      "| 4883283|2011-06-22 00:51:53|       12.1|2011-06-22 01:51:53|      -74.001532|      40.732103|        -73.960319|         40.763751|              1|   1| 22|    6|      4| 4.943412115607007|[1.0,4.9434121156...|\n",
      "|25927066|2011-03-22 08:10:53|        4.9|2011-03-22 08:10:53|      -73.987643|      40.776225|        -73.980739|          40.76577|              1|   8| 22|    3|      3|1.2998160868325819|[1.0,1.2998160868...|\n",
      "|   89146|2012-04-02 12:57:55|       12.1|2012-04-02 13:57:55|      -73.963302|      40.771868|        -73.993812|         40.731875|              1|  13|  2|    4|      2| 5.136236647872253|[1.0,5.1362366478...|\n",
      "+--------+-------------------+-----------+-------------------+----------------+---------------+------------------+------------------+---------------+----+---+-----+-------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- key: timestamp (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- distance_km: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "Row count: 193063\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "df.printSchema()\n",
    "print(\"Row count:\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c688b-a5be-49e8-97af-3c501719e9d9",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23726932-16dd-42fe-83fe-da11f9fcabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train-test split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1aa0ec-d65d-4127-878c-1f458b0a90cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance (MAE, RMSE, R2):\n",
      "\n",
      "Linear Regression: MAE=2.42, RMSE=5.51, R2=0.678\n",
      "Decision Tree: MAE=2.45, RMSE=5.14, R2=0.721\n",
      "Random Forest: MAE=2.42, RMSE=4.93, R2=0.743\n"
     ]
    }
   ],
   "source": [
    "# 8. Train Models\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(featuresCol=\"features\", labelCol=\"fare_amount\"),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"fare_amount\", maxDepth=10),\n",
    "    \"Random Forest\": RandomForestRegressor(featuresCol=\"features\", labelCol=\"fare_amount\", numTrees=100, maxDepth=10)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "evaluator = RegressionEvaluator(labelCol=\"fare_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    fitted_model = model.fit(train_df)\n",
    "    predictions = fitted_model.transform(test_df)\n",
    "    mae = RegressionEvaluator(labelCol=\"fare_amount\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(predictions)\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    r2 = RegressionEvaluator(labelCol=\"fare_amount\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(predictions)\n",
    "    results[name] = (mae, rmse, r2)\n",
    "# 9. Display Results\n",
    "print(\"Model Performance (MAE, RMSE, R2):\\n\")\n",
    "for name, (mae, rmse, r2) in results.items():\n",
    "    print(f\"{name}: MAE={mae:.2f}, RMSE={rmse:.2f}, R2={r2:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
